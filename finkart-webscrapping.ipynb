{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3580c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import request\n",
    "import urllib.request as ur\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting input for webiste from user\n",
    "urlinput = input(\"Enter url :\")\n",
    "print(\" This is the website link that you entered\", urlinput)\n",
    "\n",
    "# For extracting specific tags from webpage\n",
    "def getTags(tag):\n",
    "  s = ur.urlopen(urlinput)\n",
    "  soup = BeautifulSoup(s.read())\n",
    "  return soup.findAll(tag)\n",
    "\n",
    "# For extracting specific title & meta description from webpage\n",
    "def titleandmetaTags():\n",
    "    s = ur.urlopen(urlinput)\n",
    "    soup = BeautifulSoup(s.read())\n",
    "    #----- Extracting Title from website ------#\n",
    "    title = soup.title.string\n",
    "    print ('Website Title is :', title)\n",
    "    #-----  Extracting Meta description from website ------#\n",
    "    meta_description = soup.find_all('meta')\n",
    "    for tag in meta_description:\n",
    "        if 'name' in tag.attrs.keys() and tag.attrs['name'].strip().lower() in ['description', 'keywords']:\n",
    "            #print ('NAME    :',tag.attrs['name'].lower())\n",
    "            print ('CONTENT :',tag.attrs['content'])\n",
    "\n",
    "#------------- Main ---------------#\n",
    "if __name__ == '__main__':\n",
    "  titleandmetaTags()\n",
    "  tags = getTags('h1')\n",
    "  for tag in tags:\n",
    "     print(tag) # display tags \n",
    "     print(tag.contents) # display contents of the tags\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import request\n",
    "import urllib.request as ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting input for webiste from user\n",
    "url_input = input(\"Enter url :\")\n",
    "print(\" This is the website link that you entered\", url_input)\n",
    "\n",
    "\n",
    "# For extracting specific tags from webpage\n",
    "def getTags(tag):\n",
    "  s = ur.urlopen(url_input)\n",
    "  soup = BeautifulSoup(s.read())\n",
    "  return soup.findAll(tag)\n",
    "\n",
    "# For extracting all h1-h6 heading tags from webpage\n",
    "def headingTags(headingtags):\n",
    "  h = ur.urlopen(url_input)\n",
    "  soup = BeautifulSoup(h.read())\n",
    "  print(\"List of headings from headingtags function h1, h2, h3, h4, h5, h6 :\")\n",
    "  for heading in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "    print(heading.name + ' ' + heading.text.strip())\n",
    "\n",
    "# For extracting specific title & meta description from webpage\n",
    "def titleandmetaTags():\n",
    "    s = ur.urlopen(urlinput)\n",
    "    soup = BeautifulSoup(s.read())\n",
    "    #----- Extracting Title from website ------#\n",
    "    title = soup.title.string\n",
    "    print ('Website Title is :', title)\n",
    "    #-----  Extracting Meta description from website ------#\n",
    "    meta_description = soup.find_all('meta')\n",
    "    for tag in meta_description:\n",
    "        if 'name' in tag.attrs.keys() and tag.attrs['name'].strip().lower() in ['description', 'keywords']:\n",
    "            #print ('NAME    :',tag.attrs['name'].lower())\n",
    "            print ('CONTENT :',tag.attrs['content'])\n",
    "\n",
    "\n",
    "\n",
    "#------------- Main ---------------#\n",
    "if __name__ == '__main__':\n",
    "  titleandmetaTags()\n",
    "  tags = getTags('p')\n",
    "  headtags = headingTags('h1')\n",
    "  for tag in tags:\n",
    "     print(\" Here are the tags from getTags function:\", tag.contents)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as ur\n",
    "\n",
    "url_input = input(\"Enter url :\")\n",
    "print(\"The website link that you entered is:\", url_input)\n",
    "\n",
    "def alt_tag():\n",
    "  url =  ur.urlopen(url_input)\n",
    "  htmlSource = url.read()\n",
    "  url.close()\n",
    "  soup = BeautifulSoup(htmlSource)\n",
    "  print('\\n The alt tag along with the text in the web page')\n",
    "  print(soup.find_all('img',alt= True))\n",
    "  \n",
    "\n",
    "\n",
    "#------------- Main ---------------#\n",
    "if __name__ == '__main__':\n",
    "  alt_tag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reviewing alt tags in seperate lines\n",
    "soup.find_all('img',alt= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c55d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "# Getting content from web page\n",
    "r = requests.get(\"https://techoid.co/contact-us\")\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "# For getting words within paragrphs\n",
    "text_paragraph = (''.join(s.findAll(text=True))for s in soup.findAll('p'))\n",
    "count_paragraph = Counter((x.rstrip(punctuation).lower() for y in text_paragraph for x in y.split()))\n",
    "\n",
    "# For getting words inside div tags\n",
    "text_div = (''.join(s.findAll(text=True))for s in soup.findAll('div'))\n",
    "count_div = Counter((x.rstrip(punctuation).lower() for y in text_div for x in y.split()))\n",
    "\n",
    "# Adding two counters for getting a list with words count (from most to less common)\n",
    "total = count_div + count_paragraph\n",
    "list_most_common_words = total.most_common() \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67301b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total words inside a webpage\n",
    "len(total)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of common words\n",
    "list_most_common_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
